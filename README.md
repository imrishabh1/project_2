# project_2

References:
lstm nmt model - https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html \n
German to English Translation Dataset - https://machinelearningmastery.com/develop-neural-machine-translation-system-keras/ \n
Sequence to Sequence Learning with Neural Networks - https://arxiv.org/pdf/1409.3215.pdf
nmt - https://github.com/hlamba28/Word-Level-Eng-Mar-NMT/blob/master/WordLevelEngMarNMT.ipynb
nmt with attention - https://www.tensorflow.org/tutorials/text/nmt_with_attention
Attention and Memory in Deep Learning and NLP - http://www.wildml.com/2016/01/attention-and-memory-in-deep-learning-and-nlp/
dataset - http://www.manythings.org/anki/
Word Level English to Marathi Neural Machine Translation using Encoder-Decoder Model - https://towardsdatascience.com/word-level-english-to-marathi-neural-machine-translation-using-seq2seq-encoder-decoder-lstm-model-1a913f2dc4a7
different attention-based models - https://nlp.stanford.edu/projects/nmt/
Neural Machine Translation With Attention Mechanism - https://machinetalk.org/2019/03/29/neural-machine-translation-with-attention-mechanism/

